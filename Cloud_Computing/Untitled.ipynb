{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skn\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    \n",
    "    \"\"\"\n",
    "        Récupération des data depuis le GCS Bucket\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_listing_final = None \n",
    "        self.df_price_avaibility = None \n",
    "        self.df_merge = None \n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "            Récupération des dataset sur le GCS Bucket\n",
    "        \"\"\"\n",
    "        self.df_listing_final = pd.read_csv('Data/listings_final.csv',sep=\";\",index_col=0)\n",
    "        self.df_price_avaibility = pd.read_csv('Data/price_availability.csv',sep=\";\")\n",
    "        print(\"data chargés\")\n",
    "        \n",
    "    def group_data(self):\n",
    "        \"\"\"\n",
    "            Merge des datas\n",
    "        \"\"\"\n",
    "        dataMean = self.df_price_avaibility.groupby('listing_id')['local_price'].mean()\n",
    "        self.df_merge = pd.merge(dataMean,self.df_listing_final,on='listing_id')\n",
    "        print('Data merged')\n",
    "        \n",
    "    def get_process_data(self):\n",
    "        \"\"\"\n",
    "            Lancement des différente méthode get_data()+goup_data()\n",
    "        \"\"\"\n",
    "        self.get_data()\n",
    "        return self.group_data()\n",
    "        \n",
    "        print(self.df_merge.dtypes)\n",
    "        print('Data processed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data chargés\n",
      "Data merged\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "data.get_process_data()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureRecipe:\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame()):\n",
    "        self.df_data = data\n",
    "        self.cate = []\n",
    "        self.floa = []\n",
    "        self.intt = []\n",
    "        self.drop = []\n",
    "\n",
    "    def separate_variable_types(self) -> None:\n",
    "        \"\"\" TODO : Diviser les types de variables dans un tableau \"\"\"\n",
    "        #variables = self.df_data.dtypes\n",
    "        #var_tab = Arrays('int64',['125946'])\n",
    "        #print(var_tab[int64])\n",
    "        \n",
    "        \"\"\"correction\"\"\"\n",
    "        print(\"separating columns\")\n",
    "        for col in self.df_data.columns:\n",
    "            if self.df_data[col].dtypes == int:\n",
    "                self.intt.append(self.df_data[col])\n",
    "            elif self.df_data[col].dtypes == float:\n",
    "                self.floa.append(self.df_data[col])\n",
    "            else:\n",
    "                self.cate.append(self.df_data[col])\n",
    "        print (\"dataset column size : {} \\nnumber of discreet values : {} \\nnumber of continuous values : {} \\nnumber of others : {} \\ntaille total : {}\".format(len(self.df_data.columns),len(self.intt),len(self.floa),len(self.cate),len(self.intt)+len(self.floa)+len(self.cate) ))\n",
    "\n",
    "        \n",
    "    def drop_uselessf(self):\n",
    "        \"\"\" TODO : Supprimer les colonnes inutiles du dataset \"\"\"\n",
    "        colonnes_drop=['is_rebookable',\n",
    "                       'is_new_listing',\n",
    "                       'is_fully_refundable',\n",
    "                       'is_host_highly_rated',\n",
    "                       'is_business_travel_ready'\n",
    "                      ]\n",
    "        \n",
    "        #for i in colonnes_drop: \n",
    "            #del data[i]\n",
    "        self.df_data.drop(columns=colonnes_drop)\n",
    "    \n",
    "        \n",
    "        \"\"\"to_drop = ['is_rebookable','is_new_listing','is_fully_refundable','is_business_travel_ready']\n",
    "        self.df.drop(columns=to_drop, inplace=True)\"\"\"\n",
    "        \n",
    "        \n",
    "    \n",
    "    def drop_duplicate(self):\n",
    "        \"\"\" TODO : Supprimer les lignes dupliquées du dataset \"\"\"\n",
    "        a=0\n",
    "        for i in self.df_data:\n",
    "            a+=1\n",
    "            b=0\n",
    "            for j in self.df_data:\n",
    "                b +=1\n",
    "                if a != b and self.df_data[i].equals(self.df_data[j]) == True:\n",
    "                    self.df_data.drop(columns=j)\n",
    "                    print('{} supprimée'.format(j))\n",
    "        \n",
    "    def drop_nanp(self, threshold: float):\n",
    "        \"\"\" TODO : Supprimer un pourcentage de NA du dataset \"\"\"\n",
    "        shape = self.df_data.shape\n",
    "        for i in self.df_data:\n",
    "            NaN = self.df_data[i].isna().sum()\n",
    "            result = (NaN/shape[0])*100\n",
    "            if result>threshold:\n",
    "                self.df_data.drop(columns=[i],inplace=True)\n",
    "                \n",
    "    def deal_dtime(self):\n",
    "        \"\"\" TODO : Traiter les DateTime \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, threshold: float):\n",
    "        self.separate_variable_types()\n",
    "        self.drop_uselessf()\n",
    "        self.drop_duplicate()\n",
    "        self.drop_nanp(threshold)\n",
    "        #self.deal_dtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data chargés\n",
      "Data merged\n",
      "separating columns\n",
      "dataset column size : 19 \n",
      "number of discreet values : 0 \n",
      "number of continuous values : 6 \n",
      "number of others : 13 \n",
      "taille total : 19\n",
      "is_business_travel_ready supprimée\n",
      "is_rebookable supprimée\n"
     ]
    }
   ],
   "source": [
    "data = DataHandler()\n",
    "data.get_process_data()\n",
    "feature = FeatureRecipe(data.df_merge)\n",
    "feature.prepare_data(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Feature Extractor class\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame, flist: list):\n",
    "        \"\"\"\n",
    "            Input : pandas.DataFrame, feature list to drop\n",
    "            Output : X_train, X_test, y_train, y_test according to sklearn.model_selection.train_test_split\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None,None,None,None\n",
    "        self.df = data\n",
    "        self.flist = flist\n",
    "    \n",
    "    def extract(self):\n",
    "        print(\"Début Extraction\")\n",
    "        self.data.drop(self.flist, axis=\"1\", inplace=True)\n",
    "        print(\"Fin Extraction\")\n",
    "        \n",
    "    def splitting(size:float,rng:int,X : pd.Series):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test,train_test_split(X, y, size, rng)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    \"\"\"\n",
    "        Class for train and print results of ml model \n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: str = None, save: bool = None):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        pass\n",
    "    def predict_test(self, X) -> np.ndarray:\n",
    "        pass\n",
    "    def predict_from_dump(self, X) -> np.ndarray:\n",
    "        pass\n",
    "    def save_model(self, path:str):\n",
    "        #with the format : 'model_{}_{}'.format(date)\n",
    "        pass\n",
    "    def print_accuracy(self):\n",
    "        pass\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            #load model\n",
    "            pass\n",
    "        except:\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
